# ai-stakeholders-ontology

Will gradually be something.

- [Competency questions](competency-questions.md)
- [Relationships](relationships.md)

## References
- [Ontology Development 101: A Guide to Creating Your First Ontology](http://www.ksl.stanford.edu/people/dlm/papers/ontology-tutorial-noy-mcguinness-abstract.html) [[PDF](https://protege.stanford.edu/publications/ontology_development/ontology101.pdf)]
- [Serving Linked Data: A Step-by-Step Tutorial](https://github.com/chrdebru/linked-data-frontend-tutorial) by Christophe Debruyne

## Why we having this?

The ontology should lead to an ability of human and machine to address these 8 key themes + International Human Rights

- Privacy
- Accountability
- Safety and Security (including Predictability)
- Transparency and Explainability
- Fairness and Non-discrimination
- Human Control of Technology
- Professional Responsibility (including Accuracy)
- Promotion of Human Values
- International Human Rights

(from Fjeld, Jessica and Achten, Nele and Hilligoss, Hannah and Nagy, Adam and Srikumar, Madhulika, Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI (January 15, 2020). Berkman Klein Center Research Publication No. 2020-1. Available at SSRN: https://ssrn.com/abstract=3518482 or http://dx.doi.org/10.2139/ssrn.3518482 )

From a perspective of human-computer interaction, we may add this as well:

- Cultural sensitivity (including ways to interact with human, like choices of words - like in surface realisation part of natural language generation)

Rationales toward the design of governance systems:

- Instrumental rationale (accuracy, etc) - tends to be "ex ante" (before the event)
- Justificatory rationale (justification of having the AI/algorithmic decision-making system in the first place)
- Dignitary rationale (autonomy + dignity)

(from *Understanding Transparency in Algorithmic Accountability* - Margot E. Kaminski)


## Refs
- Guidelines for Human-AI Interaction https://dl.acm.org/doi/10.1145/3290605.3300233 
- Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making https://dl.acm.org/doi/10.1145/3290605.3300234 
